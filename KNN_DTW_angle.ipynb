{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/silcheon/UROP_project/blob/master/squat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcBlWEipOZBK"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "QS_dnNzcOq3G"
   },
   "outputs": [],
   "source": [
    "#!ls\n",
    "#%cd /content/drive\n",
    "#%cd MyDrive\n",
    "#%cd drive/MyDrive/UROP2/UROP_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "haCUW0XEP-iT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import utils\n",
    "\n",
    "from parse import load_ps\n",
    "from pprint import pprint\n",
    "from scipy.signal import medfilt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "cfd1i-C7Amjv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['squat_good_12.npy', 'squat_good_15.npy', 'squat_good_13.npy',\n",
      "       'squat_good_14.npy', 'squat_good_5.npy', 'squat_good_8.npy',\n",
      "       'squat_good_6.npy', 'squat_bad_4.npy', 'squat_good_16.npy',\n",
      "       'squat_good_17.npy', 'squat_good_11.npy'], dtype='<U17')\n",
      "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])\n",
      "array(['squat_bad_7.npy', 'squat_bad_8.npy', 'squat_good_7.npy',\n",
      "       'squat_good_10.npy', 'squat_good_9.npy'], dtype='<U17')\n",
      "array([0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "files = utils.files_in_order('poses_compressed/squat')\n",
    "\n",
    "X_train_names, X_test_names = train_test_split(files, test_size=0.3, random_state=39)\n",
    "y_train = utils.get_labels(X_train_names)\n",
    "y_test = utils.get_labels(X_test_names)\n",
    "\n",
    "\n",
    "pprint(X_train_names)\n",
    "pprint(y_train)\n",
    "pprint(X_test_names)\n",
    "pprint(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "BBKkJXXSBRnQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['squat_good_12.npy' 'squat_good_15.npy' 'squat_good_13.npy'\n",
      " 'squat_good_14.npy' 'squat_good_5.npy' 'squat_good_8.npy'\n",
      " 'squat_good_6.npy' 'squat_bad_4.npy' 'squat_good_16.npy'\n",
      " 'squat_good_17.npy' 'squat_good_11.npy']\n",
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nX_train_1=load_features(X_train_names,0)\\nX_train_2=load_features(X_train_names,0)\\nX_test_1=load_features(X_test_names, 0)\\nX_test_2=load_features(X_test_names, 0)\\nX_new_names = ['test.npy']\\nX_new_1= load_features(X_new_names, 1)\\nX_new_2= load_features(X_new_names, 1)\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_features(names, flag):\n",
    "    output1 = [] # List of upper arm torso angles\n",
    "    output2 = [] # List of upper_leg_under_leg_angle\n",
    "    output3 = [] # List of under_leg_ground_angle\n",
    "    \n",
    "    for filename in names:\n",
    "        if flag == 0: # flag 0 이면 기존 training, test \n",
    "            ps = load_ps('poses_compressed/squat/'+filename)\n",
    "        else: # 1 flag 이면 새로 만든 값\n",
    "            ps = load_ps('numpy/'+filename)\n",
    "        \n",
    "        poses = ps.poses\n",
    "\n",
    "        right_present = [1 for pose in poses \n",
    "                if pose.rankle.exists and pose.rknee.exists and pose.rhip.exists]\n",
    "        left_present = [1 for pose in poses\n",
    "                if pose.lankle.exists and pose.lknee.exists and pose.lhip.exists]\n",
    "        right_count = sum(right_present)\n",
    "        left_count = sum(left_present)\n",
    "        side = 'right' if right_count > left_count else 'left'\n",
    "\n",
    "        if side == 'right':\n",
    "            joints = [(pose.rankle, pose.rknee, pose.rhip, pose.neck) for pose in poses]\n",
    "        else:\n",
    "            joints = [(pose.lankle, pose.lknee, pose.lhip,pose.neck) for pose in poses]\n",
    "\n",
    "        # filter out data points where a part does not exist\n",
    "        joints = [joint for joint in joints if all(part.exists for part in joint)]\n",
    "        \n",
    "        torso_vecs = np.array([(joint[3].x - joint[2].x, joint[3].y - joint[2].y) for joint in joints])#몸통벡터\n",
    "        upper_leg_vecs = np.array([(joint[2].x - joint[1].x, joint[2].y - joint[1].y) for joint in joints])#허벅지 벡터\n",
    "        under_leg_vecs = np.array([(joint[1].x - joint[0].x, joint[1].y - joint[0].y) for joint in joints])#정강이 벡터\n",
    "        ground_vecs=np.array([((joint[0].x)+4,0) for joint in joints])#x축과 평행한 벡터(땅벡터)\n",
    "\n",
    "        torso_vecs = torso_vecs / np.expand_dims(np.linalg.norm(torso_vecs, axis=1), axis=1)\n",
    "        upper_leg_vecs = upper_leg_vecs / np.expand_dims(np.linalg.norm(upper_leg_vecs, axis=1), axis=1)\n",
    "        under_leg_vecs = under_leg_vecs / np.expand_dims(np.linalg.norm(under_leg_vecs, axis=1), axis=1)\n",
    "        ground_vecs = ground_vecs / np.expand_dims(np.linalg.norm(under_leg_vecs, axis=1), axis=1)\n",
    "\n",
    "        upper_leg_torso_angle = np.degrees(np.arccos(np.clip(np.sum(np.multiply(upper_leg_vecs, torso_vecs), axis=1), -1.0, 1.0)))\n",
    "        upper_arm_torso_angle_filtered = medfilt(medfilt(upper_leg_torso_angle, 5), 5)\n",
    "        \n",
    "        upper_leg_under_leg_angle = np.degrees(np.arccos(np.clip(np.sum(np.multiply(upper_leg_vecs, under_leg_vecs), axis=1), -1.0, 1.0)))\n",
    "        upper_leg_under_leg_angle_filtered = medfilt(medfilt(upper_leg_under_leg_angle, 5), 5)\n",
    "\n",
    "        under_leg_ground_angle = np.degrees(np.arccos(np.clip(np.sum(np.multiply(under_leg_vecs, ground_vecs), axis=1), -1.0, 1.0)))\n",
    "        under_leg_ground_angle_filtered = medfilt(medfilt(under_leg_ground_angle, 5), 5)\n",
    "\n",
    "        output1.append(upper_arm_torso_angle_filtered.tolist())\n",
    "        output2.append(upper_leg_under_leg_angle_filtered.tolist())\n",
    "        output3.append(under_leg_ground_angle_filtered.tolist())\n",
    "     \n",
    "        \n",
    "    return output1, output2, output3\n",
    "\n",
    "X_train_1, X_train_2, X_train_3 = load_features(X_train_names, 0)\n",
    "X_test_1, X_test_2, X_test_3 = load_features(X_test_names, 0)\n",
    "print(X_train_names)\n",
    "print(len(X_train_1))\n",
    "\n",
    "\n",
    "'''\n",
    "X_train_1=load_features(X_train_names,0)\n",
    "X_train_2=load_features(X_train_names,0)\n",
    "X_test_1=load_features(X_test_names, 0)\n",
    "X_test_2=load_features(X_test_names, 0)\n",
    "X_new_names = ['test.npy']\n",
    "X_new_1= load_features(X_new_names, 1)\n",
    "X_new_2= load_features(X_new_names, 1)\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "GOlgvwLQEF8X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squat_bad_7.npy\n",
      "212.17982255383305 377.8869022441949\n",
      "squat_bad_8.npy\n",
      "420.55997545782554 639.8448914765709\n",
      "squat_good_7.npy\n",
      "115.39210324534784 510.00954430272424\n",
      "squat_good_10.npy\n",
      "125.27214860175084 497.2419786953535\n",
      "squat_good_9.npy\n",
      "116.80300096774715 501.83850426496645\n"
     ]
    }
   ],
   "source": [
    "def KNN(X_names, X_1, X_2, X_3):\n",
    "    predictions = []\n",
    "    \n",
    "    # Store the average distance to good and bad training examples\n",
    "    f1_good, f1_bad, f2_good, f2_bad, f3_good, f3_bad = [[] for i in range(6)]\n",
    "\n",
    "    # Compare distance of current test example with all training examples\n",
    "    for i in range(len(X_train_1)):\n",
    "        dist1 = utils.DTWDistance(X_train_1[i], X_1)\n",
    "        dist2 = utils.DTWDistance(X_train_2[i], X_2)\n",
    "        dist3 = utils.DTWDistance(X_train_3[i], X_3)\n",
    "            \n",
    "        if y_train[i]:\n",
    "            f1_good.append(dist1)\n",
    "            f2_good.append(dist2)\n",
    "            f3_good.append(dist3)\n",
    "                \n",
    "        else:\n",
    "            f1_bad.append(dist1)\n",
    "            f2_bad.append(dist2)\n",
    "            f3_bad.append(dist3)\n",
    "                \n",
    "    good_score = np.mean(f1_good) + np.mean(f2_good) + np.mean(f3_good)\n",
    "    bad_score  = np.mean(f1_bad) + np.mean(f2_bad) + np.mean(f3_bad)\n",
    "\n",
    "    print(good_score, bad_score)\n",
    "    \n",
    "    #print(good_score, bad_score)\n",
    "    # dist가 크면 유사도가 적다\n",
    "    # bad score가 크면 good\n",
    "    if good_score < bad_score:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "result = []\n",
    "for i in range(len(X_test_names)) :\n",
    "    print(X_test_names[i])\n",
    "    test_label = KNN(X_train_names, X_test_1[i], X_test_2[i], X_test_3[i]) # 기존 test data \n",
    "    result.append([X_test_names[i], test_label])\n",
    "    \n",
    "#print(X_test_names)\n",
    "# KNN(X_new_names, X_new_1, X_new_2) # 영상에서 새로 추출한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "rcdomHduEWI3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## TRAIN SET ##\n",
      "squat_good_12.npy Good\n",
      "squat_good_15.npy Good\n",
      "squat_good_13.npy Good\n",
      "squat_good_14.npy Good\n",
      "squat_good_5.npy Good\n",
      "squat_good_8.npy Good\n",
      "squat_good_6.npy Good\n",
      "squat_bad_4.npy Bad\n",
      "squat_good_16.npy Good\n",
      "squat_good_17.npy Good\n",
      "squat_good_11.npy Good\n",
      "\n",
      "## TEST RESULT ##\n",
      "squat_bad_7.npy Good Wrong\n",
      "squat_bad_8.npy Good Wrong\n",
      "squat_good_7.npy Good Right\n",
      "squat_good_10.npy Good Right\n",
      "squat_good_9.npy Good Right\n"
     ]
    }
   ],
   "source": [
    "print(\"## TRAIN SET ##\")\n",
    "for i in range(len(X_train_names)) : \n",
    "    print(X_train_names[i], end = \" \")\n",
    "    if y_train[i] == 1 :\n",
    "        print(\"Good\")\n",
    "    else :\n",
    "        print(\"Bad\")\n",
    "        \n",
    "        \n",
    "print(\"\\n## TEST RESULT ##\")\n",
    "for r in result : \n",
    "    ori_result = r[0].split(\"_\")[1]\n",
    "    \n",
    "    print(r[0], end = \" \")\n",
    "    if r[1] == 1 :\n",
    "        print(\"Good\", end = \" \")\n",
    "    else :\n",
    "        print(\"Bad\", end = \" \")\n",
    "\n",
    "    if ori_result == 'good' and r[1] == 1 : \n",
    "        print(\"Right\")  \n",
    "    \n",
    "    elif ori_result == 'bad' and r[1] == 0 : \n",
    "        print(\"Right\")\n",
    "        \n",
    "    else : print(\"Wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "squat.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
